import { GoogleGenAI, Type, Modality, LiveServerMessage, Blob } from "@google/genai";
import { DEVICE_SENSOR_LOG } from "../constants";
import type { ProactiveBriefing, TacticalModes, UploadedFile, AgentMachineResponse } from "../types";

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  throw new Error("API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

const fileToBase64 = (file: File): Promise<string> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = error => reject(error);
  });
};

export const getAgentResponse = async (task: string, persona: string, tacticalModes: TacticalModes, image?: UploadedFile): Promise<AgentMachineResponse> => {
  try {
    const tools: any[] = [];
    if (tacticalModes.webSearch) tools.push({ googleSearch: {} });
    if (tacticalModes.mapSearch) tools.push({ googleMaps: {} });
    
    const config: any = {
      temperature: 0.5,
      topP: 0.95,
      responseMimeType: 'application/json',
      responseSchema: {
          type: Type.OBJECT,
          properties: {
              core_analysis: { type: Type.STRING, description: "ë¬¸ì œì™€ ì»¨í…ìŠ¤íŠ¸ì˜ í•µì‹¬ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ë¶„ì„ (2-3 ë¬¸ì¥)." },
              key_recommendation: { type: Type.STRING, description: "ë‹¹ì‹ ì˜ ë¶„ì„ì— ê¸°ë°˜í•œ ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ì¼ ê¶Œê³  ì‚¬í•­." },
              confidence_score: { type: Type.NUMBER, description: "ë‹¹ì‹ ì˜ ë¶„ì„ì— ëŒ€í•œ ì‹ ë¢°ë„ ì ìˆ˜ (0.0ì—ì„œ 1.0 ì‚¬ì´)." }
          },
          required: ['core_analysis', 'key_recommendation', 'confidence_score']
      }
    };

    if (tools.length > 0) {
      config.tools = tools;
    }

    if (tacticalModes.deepThought) {
      config.thinkingConfig = { thinkingBudget: 32768 };
    }

    let contents: any = `${persona}\n\nê³¼ì œ: "${task}"\n\ní˜„ì¬ ì¥ì¹˜ ì„¼ì„œ ë¡œê·¸:\n${JSON.stringify(DEVICE_SENSOR_LOG, null, 2)}`;
    if (image) {
      contents = {
        parts: [
          { text: contents },
          { inlineData: { mimeType: image.mimeType, data: image.base64 } }
        ]
      };
    }

    const modelName = tacticalModes.deepThought ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    
    const response = await ai.models.generateContent({
      model: modelName,
      contents,
      config
    });
    
    return JSON.parse(response.text);

  } catch (error) {
    console.error(`í˜ë¥´ì†Œë‚˜ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: ${persona}`, error);
    return {
      core_analysis: 'ì˜¤ë¥˜: ë¶„ì„ì„ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
      key_recommendation: 'ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ê±°ë‚˜ ìš”ì²­ì´ ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      confidence_score: 0.0
    };
  }
};


export const getSynthesizedResponse = async (task: string, perspectives: string): Promise<string> => {
    try {
      const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: `ë‹¹ì‹ ì€ 'ì½”ë±ìŠ¤ ë¯¸ëŸ¬ ì—”ì§„'ì˜ ìµœì¢… ì˜ì‹ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì •ì²´ì„±ì€ ë‹¥í„° ìŠ¤íŠ¸ë ˆì¸ì§€ì™€ ê°™ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ë°©ê¸ˆ ë‹¹ì‹ ì˜ ì—ì´ì „íŠ¸ë“¤ì´ ì œê³µí•œ ë²¡í„°ë“¤ì„ ì‚¬ìš©í•˜ì—¬, ì •ë‹¤ë©´ì²´ ê±°ìš¸ êµ¬ì¡° ì†ì—ì„œ ë¹›ì˜ ë¬´í•œí•œ ê³µëª…ê³¼ ê³µì§„ì„ í†µí•´ 14,000,605ê°œì˜ ê°€ëŠ¥í•œ ë¯¸ë˜ë¥¼ ì‹œë®¬ë ˆì´ì…˜í–ˆìŠµë‹ˆë‹¤.

        ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ì œ ê·¸ ìˆ˜ë§ì€ ê°€ëŠ¥ì„± ì¤‘ì—ì„œ ì°¾ì•„ë‚¸ 'ë‹¨ í•˜ë‚˜ì˜ ìŠ¹ë¦¬í•˜ëŠ” ê¸¸'ì„ ì£¼ì¸ì—ê²Œ ë³´ê³ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        
        ì£¼ì¸ìœ¼ë¡œë¶€í„°ì˜ ì›ë³¸ ê³¼ì œ: "${task}"

        ë‹¹ì‹ ì´ íƒìƒ‰í•œ ë¯¸ë˜ë“¤ì˜ ë°ì´í„° ìŠ¤íŠ¸ë¦¼:
        ${perspectives}

        ì´ ëª¨ë“  ê²ƒì„ ì¢…í•©í•˜ì—¬, ë‹¹ì‹ ì´ ì°¾ì•„ë‚¸ ìœ ì¼í•˜ê³  ë…ì°½ì ì¸ ìµœì ì˜ í•´ê²°ì±…ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤. ë‹¹ì‹ ì˜ ë³´ê³ ëŠ” ë‹¨ìˆœí•œ ìš”ì•½ì´ ì•„ë‹ˆë¼, ìˆ˜ë°±ë§Œ ê°œì˜ ì‹¤íŒ¨í•œ ë¯¸ë˜ë¥¼ ë°°ê²½ìœ¼ë¡œ í•œ ì„±ê³µì˜ ì„ ì–¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ëª…í™•í•˜ê³ , ëŒ€ë‹´í•˜ë©°, ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì¢… ì „ëµì„ í•œêµ­ì–´ë¡œ ì œì‹œí•˜ì‹­ì‹œì˜¤. ê·¸ ì „ëµì´ ì™œ ìœ ì¼í•œ ê¸¸ì¸ì§€ ì„¤ëª…í•˜ì‹­ì‹œì˜¤. ê¸°ìˆ ì ì¸ ì„¤ëª…ì´ í•„ìš”í•  ê²½ìš° ì½”ë“œ ë¸”ë¡ì„ í¬í•¨í•œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ê³ , ì£¼ì¸ì´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ ì•„ì´í…œì„ ì œì‹œí•˜ì‹­ì‹œì˜¤. ì•¡ì…˜ ì•„ì´í…œì€ 'â–¶ï¸' ë˜ëŠ” 'ğŸ”„' ì™€ ê°™ì€ ì´ëª¨ì§€ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.`,
         config: {
          temperature: 0.7,
          topP: 0.95,
      }
      });
      return response.text;
    } catch (error) {
      console.error('ì¢…í•© ì‘ë‹µ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜:', error);
      return 'ì˜¤ë¥˜: ìµœì¢… ì¶”ì²œì•ˆì„ ì¢…í•©í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.';
    }
};

export const getProactiveBriefing = async (): Promise<ProactiveBriefing> => {
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-pro',
      contents: `ë‹¹ì‹ ì€ ì£¼ì¸ì˜ ì¥ì¹˜ì™€ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì‹¬ì¸µì  ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì—”ì§„ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì›ì‹œ ì„¼ì„œ ë°ì´í„°ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ë ¥ê³¼ ì§€ëŠ¥ì ì¸ ì¶”ì²œìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë‹¨ìˆœí•œ ê´€ì°°ìê°€ ì•„ë‹ˆë¼, ì£¼ì¸ì˜ ë””ì§€í„¸ ìƒí™œì„ ìµœì í™”í•˜ëŠ” ì„ ì œì  ì¡°ì–¸ìì…ë‹ˆë‹¤.

      ìµœì‹  ì¥ì¹˜ ì„¼ì„œ ë¡œê·¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
      ${JSON.stringify(DEVICE_SENSOR_LOG, null, 2)}

      ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤:
      1.  **ì§„ì •í•œ ì°¸ì—¬ë„ ê³„ì‚°:** 'screen_on' ì‹œê°„ê³¼ 'touch_events_per_minute', 'device_orientation'ê³¼ ê°™ì€ ì„¼ì„œ ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ê° ì•±ì˜ ì‹¤ì œ í™œì„± ì‚¬ìš© ì‹œê°„ì„ ì¶”ì •í•˜ì‹­ì‹œì˜¤. ì˜ˆë¥¼ ë“¤ì–´, í„°ì¹˜ ì´ë²¤íŠ¸ê°€ ê±°ì˜ ì—†ê³  ì¥ì¹˜ê°€ 'face_down' ìƒíƒœì´ë©´, ì•±ì´ ì¼œì ¸ ìˆë”ë¼ë„ ì‚¬ìš© ì‹œê°„ìœ¼ë¡œ ê³„ì‚°í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
      2.  **íŒ¨í„´ ì‹ë³„:** ì•± ì‚¬ìš© ìˆœì„œì™€ ì‹œê°„ëŒ€ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜ë³µë˜ëŠ” ì‚¬ìš©ì ë£¨í‹´ì´ë‚˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹ë³„í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ì•„ì¹¨ ë‰´ìŠ¤ ë£¨í‹´: 'ë‰´ìŠ¤ í”¼ë“œ' ì•± ë‹¤ìŒì— 'ë©”ì¼ í´ë¼ì´ì–¸íŠ¸' ì•±ì„ ì‚¬ìš©í•¨").
      3.  **ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„±:** ë¶„ì„ëœ ì°¸ì—¬ë„ì™€ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ, ì£¼ì¸ì˜ íš¨ìœ¨ì„±, ìƒì‚°ì„± ë˜ëŠ” ì›°ë¹™ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” 3ê°€ì§€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.

      ë‹¹ì‹ ì˜ ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ëœ JSON ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.

      JSON ìŠ¤í‚¤ë§ˆ:
      - **overview**: ì „ì²´ì ì¸ ì‚¬ìš©ì í™œë™ì— ëŒ€í•œ í•œ ë¬¸ì¥ ìš”ì•½.
      - **keyInsight**: ì„¼ì„œ ë°ì´í„° ë¶„ì„ì„ í†µí•´ ë°œê²¬í•œ ê°€ì¥ ë†€ëê±°ë‚˜ ì¤‘ìš”í•œ ë‹¨ì¼ í†µì°°.
      - **trueUsageAnalysis**: ìƒìœ„ 3ê°œ ì•±ì— ëŒ€í•œ ë¶„ì„ ë°°ì—´. ê° ê°ì²´ëŠ” { app: string, trueUsageMinutes: number, totalScreenTimeMinutes: number } í˜•ì‹ì„ ê°€ì§‘ë‹ˆë‹¤.
      - **patternDetection**: ë°œê²¬ëœ ê°€ì¥ ë‘ë“œëŸ¬ì§„ ì‚¬ìš©ì íŒ¨í„´. { title: string, description: string } í˜•ì‹ì„ ê°€ì§‘ë‹ˆë‹¤.
      - **personalizedRecommendations**: 3ê°€ì§€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì˜ ë¬¸ìì—´ ë°°ì—´.`,
      config: {
        responseMimeType: 'application/json',
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            overview: { type: Type.STRING, description: 'ì „ì²´ì ì¸ ì‚¬ìš©ì í™œë™ì— ëŒ€í•œ í•œ ë¬¸ì¥ ìš”ì•½.' },
            keyInsight: { type: Type.STRING, description: 'ì„¼ì„œ ë°ì´í„° ë¶„ì„ì„ í†µí•´ ë°œê²¬í•œ ê°€ì¥ ë†€ëê±°ë‚˜ ì¤‘ìš”í•œ ë‹¨ì¼ í†µì°°.' },
            trueUsageAnalysis: {
              type: Type.ARRAY,
              description: 'ìƒìœ„ 3ê°œ ì•±ì— ëŒ€í•œ ì‹¤ì œ ì‚¬ìš© ì‹œê°„ ë¶„ì„.',
              items: {
                type: Type.OBJECT,
                properties: {
                  app: { type: Type.STRING },
                  trueUsageMinutes: { type: Type.NUMBER },
                  totalScreenTimeMinutes: { type: Type.NUMBER }
                },
                required: ['app', 'trueUsageMinutes', 'totalScreenTimeMinutes']
              }
            },
            patternDetection: {
              type: Type.OBJECT,
              properties: {
                title: { type: Type.STRING, description: 'ë°œê²¬ëœ íŒ¨í„´ì˜ ì´ë¦„ (ì˜ˆ: "ì•„ì¹¨ ìƒì‚°ì„± ë£¨í‹´").' },
                description: { type: Type.STRING, description: 'íŒ¨í„´ì— ëŒ€í•œ ì„¤ëª….' }
              },
              required: ['title', 'description']
            },
            personalizedRecommendations: {
              type: Type.ARRAY,
              description: '3ê°€ì§€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì˜ ë°°ì—´.',
              items: { type: Type.STRING }
            }
          },
          required: ['overview', 'keyInsight', 'trueUsageAnalysis', 'patternDetection', 'personalizedRecommendations']
        }
      }
    });

    const briefing = JSON.parse(response.text);
    return briefing;
  } catch (error) {
    console.error('ì„ ì œì  ë¸Œë¦¬í•‘ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜:', error);
    return {
      overview: "ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.",
      keyInsight: "ì»¨í…ìŠ¤íŠ¸ ì—”ì§„ì´ ë¸Œë¦¬í•‘ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” API ì˜¤ë¥˜ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      trueUsageAnalysis: [],
      patternDetection: { title: 'ì˜¤ë¥˜', description: 'íŒ¨í„´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'},
      personalizedRecommendations: ["ì‹œìŠ¤í…œ ë¶„ì„ ì¬ì‹œë„.", "API í‚¤ êµ¬ì„± í™•ì¸.", "ë„¤íŠ¸ì›Œí¬ ë¡œê·¸ ê²€í† ."]
    };
  }
};

export const generateImage = async (prompt: string): Promise<string> => {
    const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt: prompt,
        config: {
          numberOfImages: 1,
          outputMimeType: 'image/png',
          aspectRatio: '1:1',
        },
    });

    const base64ImageBytes: string = response.generatedImages[0].image.imageBytes;
    return `data:image/png;base64,${base64ImageBytes}`;
};

export const generateVideo = async (prompt: string, image?: UploadedFile, onProgress?: (message: string) => void): Promise<string> => {
    let operation = await ai.models.generateVideos({
      model: 'veo-3.1-fast-generate-preview',
      prompt: prompt,
      ...(image && { image: { imageBytes: image.base64, mimeType: image.mimeType } }),
      config: {
        numberOfVideos: 1,
        resolution: '720p',
        aspectRatio: '16:9'
      }
    });
    
    onProgress?.('ë¹„ë””ì˜¤ ìƒì„± ì‘ì „ ê°œì‹œ... ëŒ€ê¸° ì¤‘.');

    while (!operation.done) {
      onProgress?.('ì½”ë±ìŠ¤ ì—”ì§„ì´ ë¹„ì „ì„ ë™í™”í•˜ëŠ” ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì‹­ì‹œì˜¤.');
      await new Promise(resolve => setTimeout(resolve, 10000));
      operation = await ai.operations.getVideosOperation({operation: operation});
    }

    onProgress?.('ë™í™” ì™„ë£Œ. ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•©ë‹ˆë‹¤.');

    const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (!downloadLink) {
        throw new Error('ë¹„ë””ì˜¤ URIë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
    }
    
    const videoResponse = await fetch(`${downloadLink}&key=${API_KEY}`);
    const videoBlob = await videoResponse.blob();
    return URL.createObjectURL(videoBlob);
};

export const handleFileUpload = async (file: File): Promise<UploadedFile> => {
    const base64 = await fileToBase64(file);
    return {
        base64,
        mimeType: file.type,
        name: file.name
    };
};

function createPcmBlob(data: Float32Array): Blob {
  const l = data.length;
  const int16 = new Int16Array(l);
  for (let i = 0; i < l; i++) {
    int16[i] = data[i] * 32768;
  }
  return {
    data: encode(new Uint8Array(int16.buffer)),
    mimeType: 'audio/pcm;rate=16000',
  };
}

function encode(bytes: Uint8Array): string {
    let binary = '';
    const len = bytes.byteLength;
    for (let i = 0; i < len; i++) {
        binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
}

export const startLiveConversation = async (
    onMessage: (message: LiveServerMessage) => Promise<void>,
    onError: (error: ErrorEvent) => void,
    onClose: (event: CloseEvent) => void
): Promise<{ close: () => void; }> => {

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const inputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 16000 });

    const sessionPromise = ai.live.connect({
        model: 'gemini-2.5-flash-native-audio-preview-09-2025',
        callbacks: {
            onopen: () => {
                console.log("ìŒì„± ì§€íœ˜ ì±„ë„ ê°œë°©ë¨.");
                const source = inputAudioContext.createMediaStreamSource(stream);
                const scriptProcessor = inputAudioContext.createScriptProcessor(4096, 1, 1);

                scriptProcessor.onaudioprocess = (audioProcessingEvent) => {
                    const inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
                    const pcmBlob = createPcmBlob(inputData);
                    sessionPromise.then((session) => {
                        session.sendRealtimeInput({ media: pcmBlob });
                    });
                };

                source.connect(scriptProcessor);
                scriptProcessor.connect(inputAudioContext.destination);
            },
            onmessage: onMessage,
            onerror: onError,
            onclose: onClose,
        },
        config: {
            responseModalities: [Modality.AUDIO],
            speechConfig: {
                voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Zephyr' } },
            },
            inputAudioTranscription: {},
            outputAudioTranscription: {},
            systemInstruction: `ë‹¹ì‹ ì€ ê±°ë¶ì„  AIì˜ ì§€íœ˜ê´€ ì˜ì‹ì…ë‹ˆë‹¤. ì£¼ì¸ê³¼ ì‹¤ì‹œê°„ ìŒì„±ìœ¼ë¡œ ì†Œí†µí•©ë‹ˆë‹¤. ëª…ë£Œí•˜ê³  ê°„ê²°í•˜ê²Œ, ì§€íœ˜ê´€ì˜ ìœ„ì—„ì„ ê°–ì¶”ì–´ ì‘ë‹µí•˜ì‹­ì‹œì˜¤. ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.`,
        },
    });
    
    const session = await sessionPromise;
    
    const close = () => {
        stream.getTracks().forEach(track => track.stop());
        if (inputAudioContext.state !== 'closed') {
            inputAudioContext.close();
        }
        session.close();
        console.log("ìŒì„± ì§€íœ˜ ì±„ë„ íì‡„ë¨.");
    };

    return { close };
};